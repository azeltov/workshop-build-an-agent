# Migrate to Local NIM Microservices

[NVIDIA's API Catalog](https://build.nvidia.com) is an excellent resource for discovering and evaluating many different Generative AI models. There is a wide breadth of available models, and getting started is free.

These APIs are ideal for quick starts and demos. However, for the unlimited performance and control needed in production, deploy models locally with NVIDIA NIM microservice containers.

In this excercise, we will run our LLM model locally and transition our code.

## Start the Model

```
docker run ...
```

## Update the Code

change agentic_rag.py ro use local NIM

## Test the Results

use langgraph cli, check in playground

## Keep Going!

encourage user to continue by migrating the reranking and embedding models
give links to the rerank and embedding build pages for help
